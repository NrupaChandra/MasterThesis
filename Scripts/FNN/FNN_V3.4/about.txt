about this version : 

- Has a FNN arcticture (with 0 Residual block)
- It implements nodal representation with normailzation 
-The nodal values are passed through a feedforward network that consists of:

Input Layer: A fully connected layer mapping from num_nodes to hidden_dim, followed by ReLU activation.

Shared Hidden Layer: A dense layer after residual blocks to refine features.

-Prediction Heads
The model has two separate branches:

Nodes Prediction Branch
Predicts x and y coordinates for a set of points.
Uses tanh activation to ensure values remain within a reasonable range.
Weights Prediction Branch
Predicts associated weights.
Uses softplus activation to ensure weights remain non-negative.

-It uses single precission (float 32)

-The test function while training are 9 legendre polynomials.


- During training the penalty loss is set to zero